{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa6221fe-da80-44b0-a1e9-d7874a3cc7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA not available, using CPU for YOLO\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, ttk, messagebox\n",
    "from PIL import Image, ImageTk\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "class PAUObjectDetectionApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"PAU Location Object Detector\")\n",
    "        self.root.geometry(\"1200x800\")\n",
    "        self.root.configure(bg=\"#f0f0f0\")\n",
    "        \n",
    "        # Default video paths\n",
    "        self.default_videos = [\n",
    "            r\"C:\\Users\\maxos\\CSC418\\dmoru883-dmoruCSC418\\Week 5\\Videos 1-3\\Video 1.mp4\",\n",
    "            r\"C:\\Users\\maxos\\CSC418\\dmoru883-dmoruCSC418\\Week 5\\Videos 1-3\\Video 2.mp4\",\n",
    "            r\"C:\\Users\\maxos\\CSC418\\dmoru883-dmoruCSC418\\Week 5\\Videos 1-3\\Video 3.mp4\"\n",
    "        ]\n",
    "        \n",
    "        # Correct YOLO and Haar cascade paths\n",
    "        self.yolo_base_path = r\"C:\\Users\\maxos\\CSC418\\dmoru883-dmoruCSC418\\Week 5\\cfg\\cfg\"\n",
    "        self.weights_path = os.path.join(self.yolo_base_path, \"yolov3.weights\")\n",
    "        self.cfg_path = os.path.join(self.yolo_base_path, \"yolov3.cfg\")\n",
    "        self.names_path = os.path.join(self.yolo_base_path, \"coco.names\")\n",
    "        self.face_cascade_path = r\"C:\\Users\\maxos\\CSC418\\dmoru883-dmoruCSC418\\Week 5\\haarcascade_frontalface_default.xml\"\n",
    "        \n",
    "        # Video handling variables\n",
    "        self.video_paths = []\n",
    "        self.current_video_index = 0\n",
    "        self.video_capture = None\n",
    "        self.is_playing = False\n",
    "        self.detection_enabled = True\n",
    "        self.face_detection_enabled = True  # Added face detection toggle\n",
    "        self.frame_count = 0\n",
    "        self.detection_frequency = 5\n",
    "        self.previous_detections = []\n",
    "        self.last_frame_time = 0\n",
    "        \n",
    "        # Initialize detectors\n",
    "        try:\n",
    "            self.initialize_yolo()\n",
    "            self.initialize_face_cascade()\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Initialization Error\", \n",
    "                               f\"Failed to initialize detectors: {str(e)}\\n\\n\"\n",
    "                               \"Please verify all required files are present.\")\n",
    "            sys.exit(1)\n",
    "        \n",
    "        # Create GUI elements\n",
    "        self.create_widgets()\n",
    "        \n",
    "        # Try to load default videos\n",
    "        self.try_load_default_videos()\n",
    "\n",
    "    def initialize_yolo(self):\n",
    "        for path in [self.weights_path, self.cfg_path, self.names_path]:\n",
    "            if not os.path.exists(path):\n",
    "                raise FileNotFoundError(f\"Required YOLO file not found: {path}\")\n",
    "                \n",
    "        self.net = cv2.dnn.readNet(self.weights_path, self.cfg_path)\n",
    "        \n",
    "        if cv2.cuda.getCudaEnabledDeviceCount() > 0:\n",
    "            try:\n",
    "                self.net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "                self.net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "                print(\"Using CUDA backend for YOLO\")\n",
    "            except:\n",
    "                print(\"CUDA available but failed to initialize, falling back to CPU\")\n",
    "        else:\n",
    "            print(\"CUDA not available, using CPU for YOLO\")\n",
    "            \n",
    "        with open(self.names_path, 'r') as f:\n",
    "            self.classes = f.read().splitlines()\n",
    "            \n",
    "        self.colors = np.random.uniform(0, 255, size=(len(self.classes), 3))\n",
    "        self.output_layers = self.net.getUnconnectedOutLayersNames()\n",
    "\n",
    "    def initialize_face_cascade(self):\n",
    "        if not os.path.exists(self.face_cascade_path):\n",
    "            raise FileNotFoundError(f\"Haar cascade file not found: {self.face_cascade_path}\")\n",
    "        self.face_cascade = cv2.CascadeClassifier(self.face_cascade_path)\n",
    "        if self.face_cascade.empty():\n",
    "            raise ValueError(\"Failed to load Haar cascade classifier\")\n",
    "\n",
    "    def try_load_default_videos(self):\n",
    "        existing_videos = [path for path in self.default_videos if os.path.exists(path)]\n",
    "        if existing_videos:\n",
    "            self.video_paths = existing_videos\n",
    "            self.current_video_index = 0\n",
    "            self.load_video()\n",
    "            self.enable_control_buttons()\n",
    "            self.update_info_label()\n",
    "            self.status_bar.config(text=f\"Loaded {len(existing_videos)} default videos\")\n",
    "        else:\n",
    "            self.status_bar.config(text=\"Default videos not found. Please select videos manually.\")\n",
    "\n",
    "    def create_widgets(self):\n",
    "        style = ttk.Style()\n",
    "        style.configure('TButton', font=('Arial', 10), padding=5)\n",
    "        style.configure('TFrame', background='#f0f0f0')\n",
    "        \n",
    "        main_frame = ttk.Frame(self.root, padding=\"10\")\n",
    "        main_frame.pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        top_frame = ttk.Frame(main_frame, padding=\"5\")\n",
    "        top_frame.pack(fill=tk.X)\n",
    "        \n",
    "        selection_frame = ttk.LabelFrame(top_frame, text=\"Video Selection\", padding=\"5\")\n",
    "        selection_frame.pack(side=tk.LEFT, padx=5, pady=5, fill=tk.X, expand=True)\n",
    "        \n",
    "        self.select_btn = ttk.Button(selection_frame, text=\"Select Videos\", command=self.select_videos)\n",
    "        self.select_btn.pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        self.use_default_btn = ttk.Button(selection_frame, text=\"Use Default Videos\", command=self.use_default_videos)\n",
    "        self.use_default_btn.pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        control_frame = ttk.LabelFrame(top_frame, text=\"Video Controls\", padding=\"5\")\n",
    "        control_frame.pack(side=tk.RIGHT, padx=5, pady=5)\n",
    "        \n",
    "        self.play_btn = ttk.Button(control_frame, text=\"Play\", command=self.toggle_play, state=tk.DISABLED)\n",
    "        self.play_btn.pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        self.stop_btn = ttk.Button(control_frame, text=\"Stop\", command=self.stop_video, state=tk.DISABLED)\n",
    "        self.stop_btn.pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        self.next_btn = ttk.Button(control_frame, text=\"Next Video\", command=self.next_video, state=tk.DISABLED)\n",
    "        self.next_btn.pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        self.detection_toggle = ttk.Button(control_frame, text=\"Toggle YOLO\", command=self.toggle_detection, state=tk.DISABLED)\n",
    "        self.detection_toggle.pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        self.face_toggle = ttk.Button(control_frame, text=\"Toggle Face\", command=self.toggle_face_detection, state=tk.DISABLED)\n",
    "        self.face_toggle.pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        display_frame = ttk.Frame(main_frame, padding=\"5\")\n",
    "        display_frame.pack(fill=tk.BOTH, expand=True, pady=5)\n",
    "        \n",
    "        video_container = ttk.LabelFrame(display_frame, text=\"Video Display\", padding=\"5\")\n",
    "        video_container.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=5, pady=5)\n",
    "        \n",
    "        self.video_frame = ttk.Label(video_container)\n",
    "        self.video_frame.pack(padx=5, pady=5, fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        self.info_label = ttk.Label(video_container, text=\"No video loaded\", font=('Arial', 10))\n",
    "        self.info_label.pack(pady=5)\n",
    "        \n",
    "        results_container = ttk.LabelFrame(display_frame, text=\"Detection Results\", padding=\"5\", width=250)\n",
    "        results_container.pack(side=tk.RIGHT, fill=tk.Y, padx=5, pady=5)\n",
    "        results_container.pack_propagate(False)\n",
    "        \n",
    "        stats_frame = ttk.Frame(results_container)\n",
    "        stats_frame.pack(fill=tk.X, pady=5)\n",
    "        \n",
    "        ttk.Label(stats_frame, text=\"Detection Statistics:\", font=('Arial', 10, 'bold')).pack(anchor=tk.W)\n",
    "        self.stats_label = ttk.Label(stats_frame, text=\"No objects detected\", font=('Arial', 9))\n",
    "        self.stats_label.pack(anchor=tk.W, pady=5)\n",
    "        \n",
    "        self.results_text = tk.Text(results_container, height=20, width=30, wrap=tk.WORD, font=('Arial', 9))\n",
    "        self.results_text.pack(fill=tk.BOTH, expand=True, pady=5)\n",
    "        \n",
    "        scrollbar = ttk.Scrollbar(results_container, command=self.results_text.yview)\n",
    "        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "        self.results_text.config(yscrollcommand=scrollbar.set)\n",
    "        \n",
    "        status_frame = ttk.Frame(main_frame, padding=\"2\")\n",
    "        status_frame.pack(fill=tk.X, side=tk.BOTTOM)\n",
    "        \n",
    "        self.status_bar = ttk.Label(status_frame, text=\"Ready\", relief=tk.SUNKEN, anchor=tk.W)\n",
    "        self.status_bar.pack(fill=tk.X)\n",
    "\n",
    "    def enable_control_buttons(self):\n",
    "        self.play_btn.config(state=tk.NORMAL)\n",
    "        self.stop_btn.config(state=tk.NORMAL)\n",
    "        self.next_btn.config(state=tk.NORMAL)\n",
    "        self.detection_toggle.config(state=tk.NORMAL)\n",
    "        self.face_toggle.config(state=tk.NORMAL)\n",
    "\n",
    "    def use_default_videos(self):\n",
    "        existing_videos = [path for path in self.default_videos if os.path.exists(path)]\n",
    "        if not existing_videos:\n",
    "            messagebox.showwarning(\"Warning\", \"Default videos not found. Please check paths or select custom videos.\")\n",
    "            return\n",
    "            \n",
    "        self.video_paths = existing_videos\n",
    "        self.current_video_index = 0\n",
    "        self.load_video()\n",
    "        self.enable_control_buttons()\n",
    "        self.update_info_label()\n",
    "        self.status_bar.config(text=f\"Loaded {len(existing_videos)} default videos\")\n",
    "\n",
    "    def select_videos(self):\n",
    "        selected_paths = filedialog.askopenfilenames(\n",
    "            title=\"Select PAU Videos\",\n",
    "            filetypes=[(\"Video Files\", \"*.mp4 *.avi *.mov *.mkv\")]\n",
    "        )\n",
    "        \n",
    "        if not selected_paths:\n",
    "            return\n",
    "            \n",
    "        if len(selected_paths) > 3:\n",
    "            selected_paths = selected_paths[:3]\n",
    "            messagebox.showwarning(\"Warning\", \"Only the first 3 videos will be used\")\n",
    "        \n",
    "        self.video_paths = list(selected_paths)\n",
    "        self.current_video_index = 0\n",
    "        self.load_video()\n",
    "        self.enable_control_buttons()\n",
    "        self.update_info_label()\n",
    "        self.status_bar.config(text=f\"Loaded {len(selected_paths)} custom videos\")\n",
    "\n",
    "    def load_video(self):\n",
    "        if not self.video_paths:\n",
    "            return\n",
    "            \n",
    "        if self.video_capture:\n",
    "            self.video_capture.release()\n",
    "            self.video_capture = None\n",
    "            \n",
    "        try:\n",
    "            video_path = self.video_paths[self.current_video_index]\n",
    "            self.video_capture = cv2.VideoCapture(video_path)\n",
    "            if not self.video_capture.isOpened():\n",
    "                raise Exception(f\"Could not open video file: {video_path}\")\n",
    "                \n",
    "            self.frame_width = int(self.video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            self.frame_height = int(self.video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "            self.fps = self.video_capture.get(cv2.CAP_PROP_FPS) or 30\n",
    "            self.total_frames = int(self.video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            \n",
    "            self.is_playing = False\n",
    "            self.frame_count = 0\n",
    "            self.update_info_label()\n",
    "            self.show_current_frame()\n",
    "            \n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Failed to load video: {str(e)}\")\n",
    "            if self.video_paths:\n",
    "                self.video_paths.pop(self.current_video_index)\n",
    "                self.current_video_index = min(self.current_video_index, len(self.video_paths) - 1)\n",
    "                if self.video_paths:\n",
    "                    self.load_video()\n",
    "                else:\n",
    "                    self.status_bar.config(text=\"No valid videos available\")\n",
    "                    self.info_label.config(text=\"No video loaded\")\n",
    "\n",
    "    def toggle_play(self):\n",
    "        if not self.video_capture:\n",
    "            return\n",
    "            \n",
    "        self.is_playing = not self.is_playing\n",
    "        \n",
    "        if self.is_playing:\n",
    "            self.play_btn.config(text=\"Pause\")\n",
    "            self.status_bar.config(text=\"Playing video...\")\n",
    "            self.last_frame_time = time.time()\n",
    "            self.play_video()\n",
    "        else:\n",
    "            self.play_btn.config(text=\"Play\")\n",
    "            self.status_bar.config(text=\"Paused\")\n",
    "\n",
    "    def play_video(self):\n",
    "        if not self.is_playing or not self.video_capture:\n",
    "            return\n",
    "            \n",
    "        ret, frame = self.video_capture.read()\n",
    "        \n",
    "        if not ret:\n",
    "            self.video_capture.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            self.play_video()\n",
    "            return\n",
    "        \n",
    "        self.frame_count += 1\n",
    "        detected_objects = {}\n",
    "        \n",
    "        if self.detection_enabled and (self.frame_count % self.detection_frequency == 0):\n",
    "            frame, detected_objects = self.detect_objects(frame)\n",
    "        elif self.detection_enabled:\n",
    "            frame = self.draw_previous_detections(frame)\n",
    "            \n",
    "        if self.face_detection_enabled:\n",
    "            frame, faces = self.detect_faces(frame)\n",
    "            if faces:\n",
    "                detected_objects['face'] = faces\n",
    "                \n",
    "        if detected_objects:\n",
    "            self.update_detection_results(detected_objects)\n",
    "        \n",
    "        display_frame = self.resize_frame_to_fit(frame)\n",
    "        display_frame = cv2.cvtColor(display_frame, cv2.COLOR_BGR2RGB)\n",
    "        img = Image.fromarray(display_frame)\n",
    "        img = ImageTk.PhotoImage(image=img)\n",
    "        \n",
    "        self.video_frame.img = img\n",
    "        self.video_frame.config(image=img)\n",
    "        \n",
    "        current_time = time.time()\n",
    "        elapsed = (current_time - self.last_frame_time) * 1000\n",
    "        delay = max(1, int(1000 / self.fps - elapsed))\n",
    "        self.last_frame_time = current_time\n",
    "        \n",
    "        self.root.after(delay, self.play_video)\n",
    "\n",
    "    def resize_frame_to_fit(self, frame):\n",
    "        max_width, max_height = 800, 600\n",
    "        h, w = frame.shape[:2]\n",
    "        \n",
    "        if h > max_height or w > max_width:\n",
    "            scale = min(max_width/w, max_height/h)\n",
    "            return cv2.resize(frame, None, fx=scale, fy=scale, interpolation=cv2.INTER_AREA)\n",
    "        return frame\n",
    "\n",
    "    def detect_objects(self, frame):\n",
    "        try:\n",
    "            height, width = frame.shape[:2]\n",
    "            blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "            self.net.setInput(blob)\n",
    "            layer_outputs = self.net.forward(self.output_layers)\n",
    "            \n",
    "            boxes, confidences, class_ids = [], [], []\n",
    "            \n",
    "            for output in layer_outputs:\n",
    "                for detection in output:\n",
    "                    scores = detection[5:]\n",
    "                    class_id = np.argmax(scores)\n",
    "                    confidence = scores[class_id]\n",
    "                    \n",
    "                    if confidence > 0.5:\n",
    "                        center_x = int(detection[0] * width)\n",
    "                        center_y = int(detection[1] * height)\n",
    "                        w = int(detection[2] * width)\n",
    "                        h = int(detection[3] * height)\n",
    "                        x = int(center_x - w / 2)\n",
    "                        y = int(center_y - h / 2)\n",
    "                        \n",
    "                        boxes.append([x, y, w, h])\n",
    "                        confidences.append(float(confidence))\n",
    "                        class_ids.append(class_id)\n",
    "            \n",
    "            indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "            detected_objects = {}\n",
    "            self.previous_detections = []\n",
    "            \n",
    "            if len(indexes) > 0:\n",
    "                for i in indexes.flatten():\n",
    "                    x, y, w, h = boxes[i]\n",
    "                    x = max(0, min(x, width - 1))\n",
    "                    y = max(0, min(y, height - 1))\n",
    "                    w = min(w, width - x)\n",
    "                    h = min(h, height - y)\n",
    "                    \n",
    "                    label = str(self.classes[class_ids[i]])\n",
    "                    confidence = round(confidences[i] * 100, 1)\n",
    "                    color = tuple(self.colors[class_ids[i]].tolist())\n",
    "                    \n",
    "                    self.previous_detections.append({\n",
    "                        'box': [x, y, w, h],\n",
    "                        'label': label,\n",
    "                        'confidence': confidence,\n",
    "                        'color': color\n",
    "                    })\n",
    "                    \n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "                    text_width = len(label) * 13 + 65\n",
    "                    cv2.rectangle(frame, (x, y - 30), (x + text_width, y), color, -1)\n",
    "                    cv2.putText(frame, f\"{label} {confidence}%\", (x, y - 10), \n",
    "                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "                    \n",
    "                    detected_objects[label] = detected_objects.get(label, 0) + 1\n",
    "            \n",
    "            return frame, detected_objects\n",
    "        except Exception as e:\n",
    "            print(f\"YOLO detection error: {str(e)}\")\n",
    "            return frame, {}\n",
    "\n",
    "    def detect_faces(self, frame):\n",
    "        try:\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            faces = self.face_cascade.detectMultiScale(\n",
    "                gray,\n",
    "                scaleFactor=1.1,\n",
    "                minNeighbors=5,\n",
    "                minSize=(30, 30)\n",
    "            )\n",
    "            \n",
    "            face_count = 0\n",
    "            for (x, y, w, h) in faces:\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, \"Face\", (x, y - 10), \n",
    "                          cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "                face_count += 1\n",
    "            \n",
    "            return frame, face_count\n",
    "        except Exception as e:\n",
    "            print(f\"Face detection error: {str(e)}\")\n",
    "            return frame, 0\n",
    "\n",
    "    def draw_previous_detections(self, frame):\n",
    "        for detection in self.previous_detections:\n",
    "            x, y, w, h = detection['box']\n",
    "            label = detection['label']\n",
    "            confidence = detection['confidence']\n",
    "            color = detection['color']\n",
    "            \n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "            text_width = len(label) * 13 + 65\n",
    "            cv2.rectangle(frame, (x, y - 30), (x + text_width, y), color, -1)\n",
    "            cv2.putText(frame, f\"{label} {confidence}%\", (x, y - 10), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        return frame\n",
    "\n",
    "    def update_detection_results(self, detected_objects):\n",
    "        self.results_text.config(state=tk.NORMAL)\n",
    "        self.results_text.delete(1.0, tk.END)\n",
    "        \n",
    "        if not detected_objects:\n",
    "            self.results_text.insert(tk.END, \"No objects detected in current frame.\")\n",
    "            self.stats_label.config(text=\"No objects detected\")\n",
    "        else:\n",
    "            total_objects = sum(detected_objects.values())\n",
    "            self.stats_label.config(text=f\"Total objects: {total_objects}\")\n",
    "            \n",
    "            sorted_objects = sorted(detected_objects.items(), key=lambda x: x[1], reverse=True)\n",
    "            self.results_text.insert(tk.END, \"Detected Objects:\\n\\n\")\n",
    "            for obj, count in sorted_objects:\n",
    "                self.results_text.insert(tk.END, f\"• {obj}: {count}\\n\")\n",
    "        \n",
    "        self.results_text.config(state=tk.DISABLED)\n",
    "\n",
    "    def stop_video(self):\n",
    "        if not self.video_capture:\n",
    "            return\n",
    "            \n",
    "        self.is_playing = False\n",
    "        self.play_btn.config(text=\"Play\")\n",
    "        self.video_capture.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        self.show_current_frame()\n",
    "        self.status_bar.config(text=\"Video stopped\")\n",
    "\n",
    "    def next_video(self):\n",
    "        if not self.video_paths:\n",
    "            return\n",
    "            \n",
    "        self.stop_video()\n",
    "        self.current_video_index = (self.current_video_index + 1) % len(self.video_paths)\n",
    "        self.load_video()\n",
    "        self.status_bar.config(text=f\"Switched to video {self.current_video_index + 1}/{len(self.video_paths)}\")\n",
    "\n",
    "    def toggle_detection(self):\n",
    "        self.detection_enabled = not self.detection_enabled\n",
    "        state_text = \"ON\" if self.detection_enabled else \"OFF\"\n",
    "        self.detection_toggle.config(text=f\"YOLO: {state_text}\")\n",
    "        \n",
    "        if not self.detection_enabled:\n",
    "            self.results_text.config(state=tk.NORMAL)\n",
    "            self.results_text.delete(1.0, tk.END)\n",
    "            self.results_text.insert(tk.END, \"YOLO detection disabled\")\n",
    "            self.results_text.config(state=tk.DISABLED)\n",
    "            self.stats_label.config(text=\"YOLO disabled\")\n",
    "        else:\n",
    "            self.frame_count = self.detection_frequency - 1\n",
    "            \n",
    "        self.status_bar.config(text=f\"YOLO Detection {state_text}\")\n",
    "\n",
    "    def toggle_face_detection(self):\n",
    "        self.face_detection_enabled = not self.face_detection_enabled\n",
    "        state_text = \"ON\" if self.face_detection_enabled else \"OFF\"\n",
    "        self.face_toggle.config(text=f\"Face: {state_text}\")\n",
    "        \n",
    "        if not self.face_detection_enabled:\n",
    "            if not self.detection_enabled:\n",
    "                self.results_text.config(state=tk.NORMAL)\n",
    "                self.results_text.delete(1.0, tk.END)\n",
    "                self.results_text.insert(tk.END, \"All detection disabled\")\n",
    "                self.results_text.config(state=tk.DISABLED)\n",
    "                self.stats_label.config(text=\"All detection disabled\")\n",
    "        self.status_bar.config(text=f\"Face Detection {state_text}\")\n",
    "\n",
    "    def show_current_frame(self):\n",
    "        if not self.video_capture or not self.video_capture.isOpened():\n",
    "            return\n",
    "            \n",
    "        current_pos = int(self.video_capture.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "        ret, frame = self.video_capture.read()\n",
    "        \n",
    "        if ret:\n",
    "            detected_objects = {}\n",
    "            if self.detection_enabled:\n",
    "                frame, detected_objects = self.detect_objects(frame)\n",
    "            if self.face_detection_enabled:\n",
    "                frame, faces = self.detect_faces(frame)\n",
    "                if faces:\n",
    "                    detected_objects['face'] = faces\n",
    "                    \n",
    "            if detected_objects:\n",
    "                self.update_detection_results(detected_objects)\n",
    "                \n",
    "            display_frame = self.resize_frame_to_fit(frame)\n",
    "            display_frame = cv2.cvtColor(display_frame, cv2.COLOR_BGR2RGB)\n",
    "            img = Image.fromarray(display_frame)\n",
    "            img = ImageTk.PhotoImage(image=img)\n",
    "            \n",
    "            self.video_frame.img = img\n",
    "            self.video_frame.config(image=img)\n",
    "        else:\n",
    "            self.video_capture.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            self.show_current_frame()\n",
    "\n",
    "    def update_info_label(self):\n",
    "        if not self.video_paths or not self.video_capture:\n",
    "            self.info_label.config(text=\"No video loaded\")\n",
    "            return\n",
    "            \n",
    "        video_name = os.path.basename(self.video_paths[self.current_video_index])\n",
    "        duration = self.total_frames / self.fps if self.fps > 0 else 0\n",
    "        minutes, seconds = divmod(int(duration), 60)\n",
    "        \n",
    "        info_text = (\n",
    "            f\"Playing: {video_name} ({self.current_video_index + 1}/{len(self.video_paths)})\\n\"\n",
    "            f\"Resolution: {self.frame_width}x{self.frame_height} | \"\n",
    "            f\"Duration: {minutes}:{seconds:02d} | \"\n",
    "            f\"FPS: {self.fps:.1f}\"\n",
    "        )\n",
    "        self.info_label.config(text=info_text)\n",
    "\n",
    "    def on_closing(self):\n",
    "        self.is_playing = False\n",
    "        if self.video_capture:\n",
    "            self.video_capture.release()\n",
    "        self.root.destroy()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        root = tk.Tk()\n",
    "        app = PAUObjectDetectionApp(root)\n",
    "        root.protocol(\"WM_DELETE_WINDOW\", app.on_closing)\n",
    "        root.mainloop()\n",
    "    except Exception as e:\n",
    "        print(f\"Application error: {str(e)}\")\n",
    "        messagebox.showerror(\"Error\", f\"Application failed to start: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcebdacb-0f5e-4f45-a4a1-dcb9a3a2e67c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f77b70-f691-4819-af39-6768c92bce0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
